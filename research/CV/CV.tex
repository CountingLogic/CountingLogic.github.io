%------------------------------------
% Dario Taraborelli
% Typesetting your academic CV in LaTeX
%
% URL: http://nitens.org/taraborelli/cvtex
% DISCLAIMER: This template is provided for free and without any guarantee 
% that it will correctly compile on your system if you have a non-standard  
% configuration.
% Some rights reserved: http://creativecommons.org/licenses/by-sa/3.0/
%------------------------------------

%!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode

\documentclass[10pt, a4paper]{article}
\usepackage{fontspec} 
\usepackage[none]{hyphenat}
\usepackage{lastpage}
\usepackage{dirtytalk}
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\usepackage[symbol]{footmisc}
% DOCUMENT LAYOUT
\usepackage{geometry} 
\geometry{a4paper, textwidth=5.5in, textheight=9.5in, marginparsep=7pt, marginparwidth=.6in}
\setlength\parindent{0in}

% FONTS
\usepackage{xunicode}
\usepackage{xltxtra}
\defaultfontfeatures{Mapping=tex-text} % converts LaTeX specials (``quotes'' --- dashes etc.) to unicode
\setromanfont [Ligatures={Common}, BoldFont={Fontin Bold}, ItalicFont={Fontin Italic}]{Fontin}
\setsansfont [Ligatures={Common}, BoldFont={Fontin Sans Bold}, ItalicFont={Fontin Sans Italic}]{Fontin Sans}
\setmonofont[Scale=0.8]{Monaco} 
% ---- CUSTOM AMPERSAND
\newcommand{\amper}{{\fontspec[Scale=.95]{Fontin}\selectfont\itshape\&}}
% ---- MARGIN YEARS
\usepackage{marginnote}
\newcommand{\years}[1]{\marginnote{\scriptsize #1}}
\renewcommand*{\raggedleftmarginnote}{}
\setlength{\marginparsep}{1pt}
\reversemarginpar

% HEADINGS
\usepackage{sectsty} 
\usepackage[normalem]{ulem} 
\sectionfont{\rmfamily\mdseries\upshape\Large}
\subsectionfont{\rmfamily\bfseries\upshape\normalsize} 
\subsubsectionfont{\rmfamily\mdseries\upshape\normalsize} 

% PDF SETUP
% ---- FILL IN HERE THE DOC TITLE AND AUTHOR
\usepackage[xetex, bookmarks, colorlinks, breaklinks, pdftitle={Sagar Malhotra - vita},pdfauthor={Sagar Malhotra}]{hyperref}  
\hypersetup{linkcolor=blue,citecolor=blue,filecolor=black,urlcolor=blue} 

\usepackage[normalem]{ulem}

% DOCUMENT
\begin{document}
{\LARGE Sagar Malhotra }\\[0.2cm]
Machine Learning Research Unit, TU Wien, Austria\\
% Information Systems Engineering Institute\\
% Faculty of Informatics\\
 

% Phone: \texttt{+39 320 841 2396}\\
Email: \href{mailto:sagar.malhotra@tuwien.ac.at}{sagar.malhotra@tuwien.ac.at}\\
\textsc{Personal website}: \href{https://countinglogic.github.io}{countinglogic.github.io}
% \textsc{DBLP}: \href{https://dblp.org/pid/38/7865.html}{38/7865}\\
% \textsc{Google Scholar}: \href{https://scholar.google.com/citations?user=EvJ5xlAAAAAJ&hl=en}{EvJ5xlAAAAAJ}\\
% \textsc{Orcid}: \href{https://orcid.org/0000-0001-6700-4311}{0000-0001-6700-4311}

%Born:  May 6, 1994\\
%Nationality:  Indian
% \section*{Personal Statement}
% I am a graduate researcher in Artificial Intelligence, working on probabilistic inference and learning in relational domains (e.g., graphs, databases, logic, etc.). My work has focused on developing efficient, expressive, and statistically consistent probabilistic relational models. Previously, I pursued a masters in physics with an exciting mix of quantitative biology and machine learning. I am passionate about solving and formulating rigorous foundational problems with a multi-disciplinary flavor. 
% I believe my background in logic, probability, physics, and machine learning can allow me to contribute significantly to research in foundational problems of emergence.
\section*{Academic Employment}
\noindent
\years{2023-now}\textsc{\textbf{Postdoctoral Researcher}}\\
Host: Prof. Thomas G\"{a}rtner\\
% Machine Learning Research Unit\\
% Information Systems Engineering Institute\\
% Faculty of Informatics\\
Machine Learning Research Unit,\\
TU Wien, Austria
% \years{2018-2019}\textsc{\textbf{Junior Research Fellow}}\\
% Advisors: Luciano Serafini, Radim Nedbal\\
% Project: Variational Inference in Hybrid Domains\\
% Data and Knowledge Management Unit\\
% Fondazione Bruno Kessler, Italy
\section*{Education}
\years{2019-2023}\textsc{\textbf{PhD in Computer Science}}\\
Thesis: On Tractability and Consistency of Probabilistic Inference in Relational Domains\\
Advisor: Luciano Serafini\\
% Data and Knowledge Management Unit\\
University of Trento, Italy\\
Fondazione Bruno Kessler, Italy (dual affiliation)\\
% Information Engineering and Computer Science Doctoral School\\

% \underline{Achievements}:
% \begin{itemize}
    % \item Provided polynomial time closed-form formulas for weighted model counting in the 2-variable fragment of first-order logic and its extensions with cardinality constraints, counting quantifiers, Directed Acyclic Graph Axiom and Connected Graph Axiom.
    % \item Provided the first non-trivial fragment of Markov Logic Networks that admits consistent parameter estimation. Showed this fragment to be complete w.r.t the 2-variable Markov Logic.
    % \item Provided an extended class of weight functions, that admit efficient weighted model counting, expanding the expressivity of many probabilistic logic frameworks.
% \end{itemize}

% \newpage
% \section*{Research Experience and Education}
%\noindent
\years{2016-2018}\textbf{MSc in Physics}\\
Advisors: Roberto Iuppa (University of Trento), Marco Cristoforetti (FBK)\\ 
Thesis: Deep Learning for Track Reconstruction in Next Generation HEP Experiments\\
Fondazione Bruno Kessler, Italy\\
University of Trento, Italy\\

\years{2012-2015}\textsc{\textbf{BSc in Physics (Honors)}}\\
University of Delhi, India

\section*{Research Interests}
I design algorithms for safe, efficient, and trustworthy machine learning (ML), focusing on formal verification and safety certification, failure-mode analysis, logic-based explainability, tractable learning and reasoning over relational data, and neurosymbolic AI. 
%\newpage

\section*{Awards and Funding}
\begin{itemize}
    \item \textbf{Honorable Mention Award} at the  International Conference on Principles of Knowledge Representation and Reasoning Conference 2024
    \item \textbf{Best Paper Award} at the International Conference of Neurosymbolic Learning and Reasoning 2024 
    % \item Project \say{Logical Distillation of Machine Learning Models} among 21/84 funding applications invited to the long proposal phase for WWTF ICT 2025 funding\\ 
    % Role: Principal Investigator, Funding requested: 793,884.00 €, Final Decision awaited
    \item ANR-FWF joint project \say{Nanostructure evolution in oxide materials at high temperature investigated with advanced X-ray scattering and machine learning based data analysis} \\Role: Part of the project team, majorly contributed towards writing the WP for machine learning. Total Funding: 1,008, 858 €. Funding for our group: 215,492 €
\end{itemize}


% \noindent

% \emph{Results from supervising Bachelor's internship of Florian Chen}\\


% \newpage
% \years{2024} \underline{Davide Bizzaro}, Luciano Serafini and \textbf{Sagar Malhotra}\\
% Towards Counting Markov Equivalence Classes with Logical Constraints\\
% \emph{Results from co-supervising Master's thesis of Davide Bizzaro}\\
% \href{https://arxiv.org/abs/2405.13736}{Under Review}\\

\newpage
% \vspace*{1em}
\section*{%
Publications\\[-.4em]%
  {\small Supervised student coauthors are \uline{underlined}.}%
}
% \vspace*{-0.5em}
% Supervised student collaborators are \underline{underlined}
% \\ \\


\subsection*{Conference Publications}
\years{2025}\underline{Alexander Pluska} and \textbf{Sagar Malhotra}\\ 
On Local Limits of Sparse Random Graphs:\\ Color Convergence and the Refined Configuration Model\\
\emph{Neural Information Processing Systems 2025.} \\
\href{https://neurips.cc/virtual/2025/poster/116124}{NeurIPS 2025} (CORE Rank \textbf{A$^{*}$}, \textbf{24.52$\%$} acceptance rate) \\   

\years{2025}\underline{Peter Blohm}, Patrick Indri, Thomas Gärtner, \textbf{Sagar Malhotra}\\ 
Probably Approximately Global Robustness Certification\\
\emph{International Conference of Machine Learning 2025.} \\
\href{https://openreview.net/forum?id=UKHlXpiFMy}{ICML 2025} (CORE Rank \textbf{A$^{*}$}, \textbf{26.9$\%$} acceptance rate) \\   

\years{2025} Steve Azzolin$^{\dagger}$, \textbf{Sagar Malhotra}$^{\dagger}$, Andrea Passerini, Stefano Teso \\
Beyond Topological Self-Explainable GNNs: A Formal Explainability Perspective\\
\emph{International Conference of Machine Learning 2025.}\\
\href{https://openreview.net/forum?id=mkqcUWBykZ}{ICML 2025} ($^{\dagger}$Equal Contribution, CORE Rank \textbf{A$^{*}$}, \textbf{26.9$\%$} acceptance rate)\\ 


% \newpage

\years{2024}\underline{Alexander Pluska}, Pascal Welke, Thomas G{\"a}rtner and \textbf{Sagar Malhotra}.\\
Logical Distillation of Graph Neural Networks\\
\emph{International Conference on Principles of Knowledge Representation and Reasoning 2024} \\
\href{https://arxiv.org/abs/2406.07126}{KR 2024} (CORE Rank \textbf{A$^{*}$}, \textbf{17\%} acceptance rate in the special track.  \textbf{Honorable Mention})\\

\years{2024}\underline{Florian Chen}, Felix Weitkämper, and \textbf{Sagar Malhotra}.\\
Understanding Domain-Size Generalization in Markov Logic Networks\\
\emph{Machine Learning and Knowledge Discovery in Databases. Research Track - European Conference} \\
\href{https://arxiv.org/abs/2403.15933}{ECML PKDD 2024} (CORE Rank \textbf{A}, \textbf{24\%} acceptance rate)\\

\years{2024}Alessandro Daniele, Tommaso Campari, \textbf{Sagar Malhotra} and Luciano Serafini\\
Simple and Effective Transfer Learning for Neuro-Symbolic Integration\\
\emph{International Conference on Neural-Symbolic Learning and Reasoning, NeSy 2024}\\
\href{https://arxiv.org/abs/2402.14047}{NeSy 2024} (\textbf{Best Paper Award})\\ 

\years{2023}Alessandro Daniele, Tommaso Campari, \textbf{Sagar Malhotra} and Luciano Serafini. \\ Deep Symbolic Learning: Discovering Symbols and Rules from Perception \\ 
\emph{International Joint Conference on Artificial Intelligence 2023}\\
\href{https://www.ijcai.org/proceedings/2023/400}{IJCAI 2023} (CORE Rank \textbf{A$^{*}$}, \textbf{15\%} acceptance rate)\\ 

% \newpage

\years{2022}\textbf{Sagar Malhotra} and Luciano Serafini\\
 On Projectivity in Markov Logic Networks \\ \emph{Machine Learning and Knowledge Discovery in Databases. Research Track - European Conference} \\  
% \textbf{Largest European conference on machine learning with $\sim$1000 submissions and an \\ acceptance rate of $\sim$25\%} 
\href{https://link.springer.com/chapter/10.1007/978-3-031-26419-1_14}{ECML PKDD 2022} (CORE Rank \textbf{A}, \textbf{26\%} acceptance rate).\\ 

% \newpage

\years{2022}\textbf{Sagar Malhotra} and Luciano Serafini\\ 
Weighted Model Counting in FO$^2$ with Cardinality Constraints and Counting Quantifiers: A Closed Form Formula \\ \emph{AAAI Conference on Artificial Intelligence 2022}\\
% \textbf{Flagship AI conference  with $\sim$10000 submissions and an  acceptance rate of  $\sim$ 10\% for oral presentations}
\href{https://ojs.aaai.org/index.php/AAAI/article/view/20525}{AAAI 2022} (CORE Rank \textbf{A$^{*}$}, \textbf{15\%} acceptance rate, \textbf{accepted as oral presentation}) \\

\years{2021}\textbf{Sagar Malhotra} and Luciano Serafini\\
 A Combinatorial Approach to Weighted Model Counting in the Two Variable Fragment with Cardinality Constraints\\ \emph{International Conference of the Italian Association for Artificial Intelligence 2019}\\
\href{https://link.springer.com/chapter/10.1007/978-3-031-08421-8_10}{AIxIA 2021}

% \newpage
\subsection*{Journal Publications}
\years{2025}\textbf{Sagar Malhotra}, \underline{Davide Bizzaro} and Luciano Serafini\\
Lifted Inference beyond First Order Logic \\
\emph{Artificial Intelligence Journal.}\\
\href{https://doi.org/10.1016/j.artint.2025.104310}{AIJ} (\textbf{Q1} Journal)
% \vspace*{-0.5em}


\subsection*{Workshop Publications (Peer-reviewed)}
% \footnotemark[\value{footnote}]}
\years{2025} \underline{Klaus Weinbauer}, Tieu-Long Phan, Peter F. Stadler,
Thomas Gärtner, and \textbf{Sagar Malhotra}\\
Prime Implicant Explanations for Reaction Feasibility Prediction\\
\emph{Workshop on Advances in Interpretable ML and AI, ECML-PKDD 2025}\\
\href{https://arxiv.org/abs/2510.09226}{AIMLAI}\\

\years{2024} Patrick Indri, \underline{Peter Blohm}, Anagha Athavale, Ezio Bartocci, Georg Weissenbacher, Matteo Maffei, Dejan Nickovic, Thomas Gärtner, \textbf{Sagar Malhotra}\\
Distillation based Robustness Verification with PAC Guarantees\\
\emph{Next Generation of AI Safety Workshop, ICML 2024}\\
\href{https://openreview.net/forum?id=vflefS3lmB}{NextGenAISafety, ICML 2024}\\

\years{2024}\underline{Alexander Pluska}, Pascal Welke, Thomas G{\"a}rtner and \textbf{Sagar Malhotra}.\\
Logical Distillation of Graph Neural Networks\\
\emph{Workshop on Mechanistic Interpretability, ICML 2024}\\
\href{https://openreview.net/forum?id=TfYnD2gYRO}{MI Workshop, ICML 2024}\\ \\
% \newpage
\years{2023}Alessandro Daniele, Tommaso Campari, \textbf{Sagar Malhotra} and Luciano Serafini. \\ Deep Symbolic Learning: Discovering Symbols and Rules from Perception \\  
\emph{International Workshop on Neural-Symbolic Learning and Reasoning 2023}\\
\href{https://sites.google.com/view/nesy2023/home/nesy2023-programme-outline?authuser=0}{NeSy 2023} (\textbf{Accepted for spotlight presentation})\\ \\
\years{2022}\textbf{Sagar Malhotra} and Luciano Serafini\\
On Projectivity in Markov Logic Networks\\ 
\emph{International Workshop on Probabilistic Logic Programming 2022}\\ \href{https://easychair.org/publications/preprint/2lTk}{ PLP 2022}\\ \\
% \newpage
% \emph{R.i.C.e.R.c.A: RCRA Incontri E Confronti, AIxIA 2022.} \href{https://ricerca2022.wordpress.com}{ R.i.C.e.R.c.A 2022}\\  \\
% \newpage
\years{2021}\textbf{Sagar Malhotra} and Luciano Serafini. Weighted Model Counting in FO$^2$ with Cardinality Constraints and Counting Quantifiers: A Closed Form Formula\\ \emph{International Workshop on Statistical Relational AI, IJCLR 2021. }\\
\href{https://starai.cs.kuleuven.be/2021/}{ StarAI, IJCLR 2021}  
% \years{{2020}}\textbf{Sagar Malhotra} and Luciano Serafini. Weighted Model Counting in C$^2$ (Abstract) \\
% \emph{Workshop on Machine Learning and Data Mining, AIxIA 2020}\\
%  \href{https://sites.google.com/view/mldm2020-workshop/program?authuser=0}{MLDM 2020}\\
%\newpage
% \section*{Under Review and Preprints}
% \years{2024}Floriann Chen,  Felix Weitkämper and \textbf{Sagar Malhotra}\\
% Understanding Domain-Size Generalization in Markov Logic Networks\\
% \emph{Under Review}\\
% \section*{Preprints\footnote[1]{Supervised students coauthors are underlined}}
% \years{2025}\underline{Peter Blohm}, Patrick Indri, Thomas Gärtner, \textbf{Sagar Malhotra}\\ 
% Probably Approximately Global Robustness Certification\\
% Under Review. 
% \href{https://countinglogic.github.io/files/Preprint.pdf}{Link} \\ \\  
% \years{2025} Steve Azzolin$^{\dagger}$, \textbf{Sagar Malhotra}$^{\dagger}$, Andrea Passerini, Stefano Teso\\
% Beyond Topological Self-Explainable GNNs: A Formal Explainability Perspective\\
% $^{\dagger}$Equal Contribution. Under Review. \href{https://arxiv.org/abs/2502.02719}{Arxiv}\\ 

% \years{2024} \underline{Davide Bizzaro}, Luciano Serafini and \textbf{Sagar Malhotra}\\
% Towards Counting Markov Equivalence Classes with Logical Constraints\\
% \emph{Results from co-supervising Master's thesis of Davide Bizzaro}\\
% \href{https://arxiv.org/abs/2405.13736}{Arxiv} 

% I can use the same footnote\footnotemark{} more than 
% once\footnotemark[\value{footnote}].
% \footnotetext{Supervised student collaborator.}

% \years{2023}\textbf{Sagar Malhotra}, Davide Bizzaro and Luciano Serafini\\
% Lifted Inference beyond First Order Logic\\
% \emph{Under Review at Artificial Intelligence Journal}\href{https://arxiv.org/abs/2302.09830}{\  arXiv:2302.09830}\\

% \years{2023}\textbf{Sagar Malhotra} and Luciano Serafini.\\
% Weighted First Order Model Counting with Directed Acyclic Graph Axiom\\
% \href{https://arxiv.org/abs/2302.09830}{arXiv:2302.09830}


% \section*{Ongoing Collaborations}
% \noindent

% Cooperative Artificial Intelligence \\
% Collaborators: Bruno Lepri (FBK, Italy), Luciano Serafini (FBK, Italy)\\ 

% Graphon Estimation and Inference for Relational Structures\\
% Collaborators: Manfred Jaeger (Aalborg University, Denmark), Luciano Serafini (FBK, Italy) 


% My research revolves around formal analysis of probability distributions over relational structures. I am especially interested in:

% $\cdot$ Random graph models and their extension to more complex relational domains\\
% $\cdot$ Exact and approximate probabilistic inference  \\
% $\cdot$ Combinatorics over relational structures\\ 
% $\cdot$ Consistency of probabilistic inference\\
% $\cdot$ Estimating asymptotic properties from sub-sampled relational structures\\
% \newpage
\section*{Talks and Tutorials}
% \noindent
\years{2025} What can logic do for safe and explainable AI?\\
\emph{Invited talk at Aachen Symposium on Representation Learning to Act and Plan, 2025}\\ 
\href{https://symposium.ml.rwth-aachen.de/#Venue}{Aachen RLeap Symposium 2025}\\ \\
\years{2025} Probabilistic Verification of Black-Box Systems\\
\emph{Spring workshop on Mining and Learning, 2025}\\ 
\href{https://dtai.cs.kuleuven.be/events/SML25/}{SMiLe 2025} \\ \\

% \newpage

\years{2024} Fundamental Problems in Statistical Relational AI\\
\emph{Half-day tutorial as a solo presenter}\\
\emph{International Conference on Principles of Knowledge Representation and Reasoning, 2024} \\
\href{https://kr.org/KR2024/workshops_tutorials.php}{KR 2024}\\ \\
\years{2024}On Consistency of Learning and Inference in Statistical Relational Learning \\
\emph{Invited Talk at MLDM Workshop at the AIxIA Conference 2024, Bolzano, Italy }\\
\href{https://sites.google.com/view/mldm2024/program?authuser=0}{MLDM 2024}\\ \\
\years{2022}On Probabilistic Inference in Logical Domains\\
\emph{Invited talk at the Institute of Informatics, Ludwig Maximilian University of Munich, Germany}\\  \\
\years{2022}A Tutorial on Probabilistic Inference in Logical Domains\\ \emph{Guest Lecture at the Knowledge representation and Learning course, University of Padova, Italy}\\ \\
\years{2022}Weighted First-Order Model Counting \\
\emph{DocInProgress Colloquium, Department of Mathematics, University of Trento, Italy} \\ \\ 
\years{2022}Weighted First-Order Model Counting\\
\emph{AAAI 2022@FBK Workshop, Trento, Italy  }\href{https://www.youtube.com/watch?v=2TRXEdq-NZg&t=3937s}{(Video)}

%%\hrule
% \section*{Programming Skills}
% \noindent 
% Fluent: Python, Pandas, \LaTeX\\
% Familiar: Mathematica, R, Pytorch, HTML



\section*{Selected Reviewing and PC Experience}
Session Chair at ECML 2024 and KR 2024

PC Member for AAAI 23-25, KR 23-25, ECAI-25 and IJCAI 24-25

Reviewer for ICML 24-25, ICLR 24-25, NeurIPS 23-25, AISTATS 23-25, ICALP 2025

Reviewer for Q1 AI/ML journals like DAMI and AIJ
% Session Chair at ECML 2024, Session Chair at KR 2024,Reviewer for  Data Mining and Knowledge Discovery Journal (Q1), Reviewer for Artificial Intelligence Journal (Q1), Reviewer ICLR 2024-25, PC member AAAI 2024-25, Reviewer NeurIPS 2023-25, PC Member KR 2023-25, PC Member IJCAI 2024-25, PC Member PLP workshop 2023-24, Reviewer ICLR 2024-25, Reviewer AISTATS 2024-25, PC Member SAC 2024, PC Member MLG Workshop-ECML 2023, Reviewer NeSy Conference 2025.
\section*{Student Supervision}
\subsection*{Master's thesis supervision}
\years{2025-Now} Michael Pritz,  TU Wien, Austria\\
% Master's thesis supervision\\ 
Title: Towards Enforcing Behaviors within
Transformers using Differentiable Constraints\\ 
\\
\years{2025} Peter Blohm,  TU Wien, Austria\\
% Master's thesis supervision\\
Title: Probabilistic Verification of Black-Box Systems\\

\years{2023} Davide Bizzaro,  University of Padova, Italy\\
% Master's thesis supervision\\
Title: Lifted Inference Beyond First Order Logic 

% \subsection*{Master's thesis supervision}

\subsection*{Other Student Supervision Roles}
    \years{2024} Florian Chen, TU Wien, Austria\\
    Role: Co-supervised in a bachelor student internship, leading to an ECML-PKDD publication\\
    % \newpage

    \years{2024} Alexander Pluska,  TU Wien, Austria\\ 
    Role: Supervised in a graduate course, leading to a conference publication at KR 2024\\ 

\years{2023-Now} Supervised multiple (10+) Bachelor’s, Master’s and PhD students in seminar courses.

% \newpage

\section*{Teaching Experience}
\years{2025W} \textbf{Neurosymbolic Reasoning (VU, 6 ECTS, MSc. and Ph.D., TU Wien)}\\
\textbf{Experience.} Teaching a new 6 ECTS course with Prof. Thomas Eiter for the Master's in Logic and AI at TU Wien. The course is a significant extension of my previous 3ECTS course on \say{Modern Applications of Logic in Machine Learning} (designed and taught as a solo-instructor). The course will introduce students to fundamentals of Neurosymbolic AI and its applications, especially for developing safe and explainable AI.  \\


\years{2025S}\textbf{Modern Applications of Logic in Machine Learning (VU, 3 ECTS, MSc. and Ph.D., TU Wien)}\\ 
\textbf{Experience:}  Responsible for creating and teaching the entire course as a \textbf{solo instructor}. Created a new curriculum for graduates students interested in recent developments on the intersection of logic and machine learning. The course consists of five inter-dependent sections: Statistical relational learning, Algorithms (model counting and MaxSAT), Neuro- \\symbolic AI, logical expressivity of ML models and Explainable AI. \\
% \begin{itemize}
    % \item \textbf{Statistical relational learning}: models that integrate logic, probability and learning e.g., Markov logic, Problog etc. 
    % \item \textbf{Algorithms}: ML relevant algorithmic problems in logic such as weighted model counting and MaxSAT 
    % \item \textbf{Neuro-symbolic integration:} models that integrate reasoning and learning in neural networks
    % \item \textbf{Explainability:} Logic based formal explainability methods like prime-implicant explanations.
    % \item \textbf{Theoretical Foundations:} role of logic in learning theory and expressivity analysis of ML models like graph neural networks and transformers. 
% \end{itemize}
\textbf{The course was well attended, with all 15 of the 15 offered places taken-up by the students. The course evaluation also showed positive results.}\\

% \newpage
\years{2023 - Now} \textbf{Introduction to Machine Learning (VU, 6 ECTS, B.Sc. $\sim$100 Students, TU Wien)}\\
\textbf{Experience:} Part of the team that designed the first edition of the course, responsible for creating and teaching the module on Probabilistic ML. I also taught the lectures for Probabilistic Machine Learning and was responsible for the office hours for various modules of the course. I developed automatically graded python based exercises that gave students hands-on experience. Also wrote a large question bank for the theoretical exam. \\ \\

 \years{2023 - Now} \textbf{Theoretical Foundations and Research Topics in Machine Learning\\ (VU, 3 ECTS, M.Sc. and Ph.D., TU Wien)}\\
 \textbf{Experience:} Responsible for conducting interactive active-learning based coursework and exercise sessions involving concepts from ML, like PAC learning, Kernel methods and GNNs.\\

 \years{2023 - Now} \textbf{Machine Learning Algorithms and Applications
(PR, 3 ECTS, M.Sc. and Ph.D., TU Wien)}\\
\textbf{Experience:} This is a project based course organized by the Machine Learning Research Unit. I have consistently offered new projects in this course. One of the offered projects led to a publication with a student, Alexander Pluska, at the \emph{International Conference on Principles of Knowledge Representation and Reasoning 2024}. \\ 

 \years{2023 - Now} \textbf{Scientific Research and Writing (SE, 3 ECTS, B.Sc., TU Wien)}\\ 
 \textbf{Experience:} This course is part of the TU Wien scientific writing course. For the practical part of the course, our research unit offers many research topics to students to write a report.
 I organize a mock-conference and peer-review procedure for reviewing the reports of the participating students.  \\

 \years{2025W-Now} \textbf{Teaching Co-ordinator for Machine Learning Research Unit, TU Wien}\\
 \textbf{Experience:} Responsible for managing the teaching coordination between the Machine Learning Research Unit and the deans of education at TU Wien. Learning to navigate administrative aspects of organizing teaching hours for the research unit.

 %  I conduct many of the exercise and course-work sessions on PAC learning and graph neural networks.

% \section*{Awards and Achievements}
% \years{2018}Bronze medal in TrackML particle tracking challenge on Kaggle.\\
% \years{2017} Part of the winning team in Industrial Problem Solving using Physics (\href{https://www.unitn.it/archivio/events/ipsp2017.html}{IPSP 2017})\\
% \years{2017}Awarded fully funded trip to Innovation Days-Innsbruck in StartUp Lab, Trento\\
% \years{2016}Awarded full Scholarship for the Joint Masters in Theoretical Physics at University of Trento and SISSA- Trieste (Declined)\\
% \years{2016}Awarded Opera Universitaria Scholarship for Masters in Physics at University of Trento\\
% \years{2016}Amongst top 5$\%$ candidates in the Joint Entrance Screening Test- Physics 2016 among $\sim$ 5000 candidates\\
% \years{2016}Amongst top 5 $\%$ candidates in IIT Joint Admission Test for Masters in Physics  2016 among $\sim$ 10000 candidates

% \newpage 

\section*{References}
Prof. Thomas Gärtner\\
% Head of Unit\\
Head of Machine Learning Research Unit\\
TU Wien, Vienna, Austria\\
Email: \href{mailto: thomas.gaertner@tuwien.ac.at}{thomas.gaertner@tuwien.ac.at} \\ 

Prof. Luciano Serafini \\
% Head of Unit\\
Head of Data and Knowledge Management Group\\
Fondazione Bruno Kessler, Trento, Italy\\
Email: \href{mailto: serafini@fbk.eu}{serafini@fbk.eu} \\ 

Prof. Andrea Passerini \\
Head of Structured Machine Learning Group\\
University of Trento, Trento, Italy \\ 
Email: \href{mailto: andrea.passerini@unitn.it}{andrea.passerini@unitn.it} \\ 

% Dr. Felix Weitkämper \\
% Institute of Informatics, LMU, Munich, Germany \\
% Email: \href{mailto: felix.weitkaemper@lmu.de}{felix.weitkaemper@lmu.de} \\ \\ 


% \vfill{}


% \begin{center}
% {\scriptsize  Last updated: \today\- •\- 
% \href{https://countinglogic.github.io/research/CV/CV.pdf}{For latest version click here. }}
% \end{center}

\end{document}