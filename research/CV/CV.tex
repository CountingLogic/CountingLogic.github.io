%------------------------------------
% Dario Taraborelli
% Typesetting your academic CV in LaTeX
%
% URL: http://nitens.org/taraborelli/cvtex
% DISCLAIMER: This template is provided for free and without any guarantee 
% that it will correctly compile on your system if you have a non-standard  
% configuration.
% Some rights reserved: http://creativecommons.org/licenses/by-sa/3.0/
%------------------------------------

%!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode

\documentclass[10pt, a4paper]{article}
\usepackage{fontspec} 
\usepackage[none]{hyphenat}
\usepackage{lastpage}
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\usepackage[symbol]{footmisc}
% DOCUMENT LAYOUT
\usepackage{geometry} 
\geometry{a4paper, textwidth=5.5in, textheight=8.5in, marginparsep=7pt, marginparwidth=.6in}
\setlength\parindent{0in}

% FONTS
\usepackage{xunicode}
\usepackage{xltxtra}
\defaultfontfeatures{Mapping=tex-text} % converts LaTeX specials (``quotes'' --- dashes etc.) to unicode
\setromanfont [Ligatures={Common}, BoldFont={Fontin Bold}, ItalicFont={Fontin Italic}]{Fontin}
\setsansfont [Ligatures={Common}, BoldFont={Fontin Sans Bold}, ItalicFont={Fontin Sans Italic}]{Fontin Sans}
\setmonofont[Scale=0.8]{Monaco} 
% ---- CUSTOM AMPERSAND
\newcommand{\amper}{{\fontspec[Scale=.95]{Fontin}\selectfont\itshape\&}}
% ---- MARGIN YEARS
\usepackage{marginnote}
\newcommand{\years}[1]{\marginnote{\scriptsize #1}}
\renewcommand*{\raggedleftmarginnote}{}
\setlength{\marginparsep}{7pt}
\reversemarginpar

% HEADINGS
\usepackage{sectsty} 
\usepackage[normalem]{ulem} 
\sectionfont{\rmfamily\mdseries\upshape\Large}
\subsectionfont{\rmfamily\bfseries\upshape\normalsize} 
\subsubsectionfont{\rmfamily\mdseries\upshape\normalsize} 

% PDF SETUP
% ---- FILL IN HERE THE DOC TITLE AND AUTHOR
\usepackage[xetex, bookmarks, colorlinks, breaklinks, pdftitle={Sagar Malhotra - vita},pdfauthor={Sagar Malhotra}]{hyperref}  
\hypersetup{linkcolor=blue,citecolor=blue,filecolor=black,urlcolor=blue} 

% DOCUMENT
\begin{document}
{\LARGE Sagar Malhotra }\\[0.2cm]
Machine Learning Research Unit, TU Wien, Austria\\
% Information Systems Engineering Institute\\
% Faculty of Informatics\\
 

% Phone: \texttt{+39 320 841 2396}\\
Email: \href{mailto:sagar.malhotra@tuwien.ac.at}{sagar.malhotra@tuwien.ac.at}\\
\textsc{Personal website}: \href{https://countinglogic.github.io}{countinglogic.github.io}
% \textsc{DBLP}: \href{https://dblp.org/pid/38/7865.html}{38/7865}\\
% \textsc{Google Scholar}: \href{https://scholar.google.com/citations?user=EvJ5xlAAAAAJ&hl=en}{EvJ5xlAAAAAJ}\\
% \textsc{Orcid}: \href{https://orcid.org/0000-0001-6700-4311}{0000-0001-6700-4311}

%Born:  May 6, 1994\\
%Nationality:  Indian
% \section*{Personal Statement}
% I am a graduate researcher in Artificial Intelligence, working on probabilistic inference and learning in relational domains (e.g., graphs, databases, logic, etc.). My work has focused on developing efficient, expressive, and statistically consistent probabilistic relational models. Previously, I pursued a masters in physics with an exciting mix of quantitative biology and machine learning. I am passionate about solving and formulating rigorous foundational problems with a multi-disciplinary flavor. 
% I believe my background in logic, probability, physics, and machine learning can allow me to contribute significantly to research in foundational problems of emergence.
\section*{Academic Employment}
\noindent
\years{2023-now}\textsc{\textbf{Postdoctoral Researcher}}\\
Host: Prof. Thomas G\"{a}rtner\\
% Machine Learning Research Unit\\
% Information Systems Engineering Institute\\
% Faculty of Informatics\\
Machine Learning Research Unit,\\
TU Wien (Technical University of Vienna), Austria
% \years{2018-2019}\textsc{\textbf{Junior Research Fellow}}\\
% Advisors: Luciano Serafini, Radim Nedbal\\
% Project: Variational Inference in Hybrid Domains\\
% Data and Knowledge Management Unit\\
% Fondazione Bruno Kessler, Italy
\section*{Education}
\years{2019-2023}\textsc{\textbf{PhD in Computer Science}}\\
Thesis: On Tractability and Consistency of Probabilistic Inference in Relational Domains\\
Advisor: Prof. Luciano Serafini\\
% Data and Knowledge Management Unit\\
University of Trento, Italy\\
Fondazione Bruno Kessler, Italy (dual affiliation)\\
% Information Engineering and Computer Science Doctoral School\\

% \underline{Achievements}:
% \begin{itemize}
    % \item Provided polynomial time closed-form formulas for weighted model counting in the 2-variable fragment of first-order logic and its extensions with cardinality constraints, counting quantifiers, Directed Acyclic Graph Axiom and Connected Graph Axiom.
    % \item Provided the first non-trivial fragment of Markov Logic Networks that admits consistent parameter estimation. Showed this fragment to be complete w.r.t the 2-variable Markov Logic.
    % \item Provided an extended class of weight functions, that admit efficient weighted model counting, expanding the expressivity of many probabilistic logic frameworks.
% \end{itemize}

% \newpage
% \section*{Research Experience and Education}
%\noindent
\years{2016-2018}\textbf{MSc in Physics}\\
% Advisors: Roberto Iuppa (Unitn), Marco Cristoforetti (FBK)\\ 
% Thesis: Deep Learning For Track Reconstruction in Next Generation HEP Experiments\\
% Fondazione Bruno Kessler, Italy\\
University of Trento, Italy\\

\years{2012-2015}\textsc{\textbf{BSc in Physics (Honors)}}\\
University of Delhi, India

\section*{Research Interests}
I am interested in algorithms for sound, efficient, and safe machine learning --- with provable mathematical guarantees. 
My interests and exprtise have allowed me to work on: tractability of learning and reasoning over relational data; logical expressivity based explainability methods; and quantitative verification of machine learning algorithms. 
%\newpage


% \noindent

% \emph{Results from supervising Bachelor's internship of Florian Chen}\\


% \newpage
% \years{2024} \underline{Davide Bizzaro}, Luciano Serafini and \textbf{Sagar Malhotra}\\
% Towards Counting Markov Equivalence Classes with Logical Constraints\\
% \emph{Results from co-supervising Master's thesis of Davide Bizzaro}\\
% \href{https://arxiv.org/abs/2405.13736}{Under Review}\\

% \newpage
\section*{Publications\protect\footnote{Supervised student coauthors are underlined.}}
% \vspace*{-1em}
% Supervised student collaborators are \underline{underlined}
% \\ \\ 
\years{2025}\textbf{Sagar Malhotra}, \underline{Davide Bizzaro} and Luciano Serafini\\
Lifted Inference beyond First Order Logic \\
\emph{Artificial Intelligence Journal.} \href{https://doi.org/10.1016/j.artint.2025.104310}{AIJ}\\ 

% \newpage

\years{2024}\underline{Alexander Pluska}, Pascal Welke, Thomas G{\"a}rtner and \textbf{Sagar Malhotra}.\\
Logical Distillation of Graph Neural Networks\\
\emph{International Conference on Principles of Knowledge Representation and Reasoning 2024} \\
\href{https://arxiv.org/abs/2406.07126}{KR 2024} (CORE Rank \textbf{A$^{*}$}, \textbf{17\%} acceptance rate in the special track.  \textbf{Honorable Mention})\\

\years{2024}\underline{Florian Chen}, Felix Weitkämper, and \textbf{Sagar Malhotra}.\\
Understanding Domain-Size Generalization in Markov Logic Networks\\
\emph{Machine Learning and Knowledge Discovery in Databases. Research Track - European Conference, ECML PKDD 2024} \\
\href{https://arxiv.org/abs/2403.15933}{ECML PKDD 2024} (CORE Rank \textbf{A}, \textbf{24\%} acceptance rate)\\

\years{2024}Alessandro Daniele, Tommaso Campari, \textbf{Sagar Malhotra} and Luciano Serafini\\
Simple and Effective Transfer Learning for Neuro-Symbolic Integration\\
International Conference on Neural-Symbolic Learning and Reasoning, NeSy 2024\\
\href{https://arxiv.org/abs/2402.14047}{NeSy 2024} (\textbf{Best Paper Award})\\ 

\years{2023}Alessandro Daniele, Tommaso Campari, \textbf{Sagar Malhotra} and Luciano Serafini. \\ Deep Symbolic Learning: Discovering Symbols and Rules from Perception \\ 
\emph{International Joint Conference on Artificial Intelligence 2023}\\
\href{https://www.ijcai.org/proceedings/2023/400}{IJCAI 2023} (CORE Rank \textbf{A$^{*}$}, \textbf{15\%} acceptance rate)\\ 


\years{2022}\textbf{Sagar Malhotra} and Luciano Serafini\\
 On Projectivity in Markov Logic Networks \\ \emph{Machine Learning and Knowledge Discovery in Databases. Research Track - European Conference, ECML PKDD 2022} \\  
% \textbf{Largest European conference on machine learning with $\sim$1000 submissions and an \\ acceptance rate of $\sim$25\%} 
\href{https://link.springer.com/chapter/10.1007/978-3-031-26419-1_14}{ECML PKDD 2022} (CORE Rank \textbf{A}, \textbf{26\%} acceptance rate).\\ 


\years{2022}\textbf{Sagar Malhotra} and Luciano Serafini\\ 
Weighted Model Counting in FO$^2$ with Cardinality Constraints and Counting Quantifiers: A Closed Form Formula \\ \emph{AAAI Conference on Artificial Intelligence 2022}\\
% \textbf{Flagship AI conference  with $\sim$10000 submissions and an  acceptance rate of  $\sim$ 10\% for oral presentations}
\href{https://ojs.aaai.org/index.php/AAAI/article/view/20525}{AAAI 2022} (CORE Rank \textbf{A$^{*}$}, \textbf{15\%} acceptance rate, \textbf{accepted as oral presentation}) \\

\years{2021}\textbf{Sagar Malhotra} and Luciano Serafini\\
 A Combinatorial Approach to Weighted Model Counting in the Two Variable Fragment with Cardinality Constraints\\ \emph{International Conference of the Italian Association for Artificial Intelligence 2019}\\
\href{https://link.springer.com/chapter/10.1007/978-3-031-08421-8_10}{AIxIA 2021}


\section*{Workshop Publications$^{*}$}
% \footnotemark[\value{footnote}]}
\years{2024} Patrick Indri, \underline{Peter Blohm}, Anagha Athavale, Ezio Bartocci, Georg Weissenbacher, Matteo Maffei, Dejan Nickovic, Thomas Gärtner, \textbf{Sagar Malhotra}\\
Distillation based Robustness Verification with PAC Guarantees\\
\emph{Next Generation of AI Safety Workshop, ICML 2024}\\
\href{https://openreview.net/forum?id=vflefS3lmB}{NextGenAISafety, ICML 2024}\\

\years{2024}\underline{Alexander Pluska}, Pascal Welke, Thomas G{\"a}rtner and \textbf{Sagar Malhotra}.\\
Logical Distillation of Graph Neural Networks\\
\emph{Workshop on Mechanistic Interpratability, ICML 2024}\\
\href{https://openreview.net/forum?id=TfYnD2gYRO}{MI Workshop, ICML 2024}\\ \\

\newpage
\years{2023}Alessandro Daniele, Tommaso Campari, \textbf{Sagar Malhotra} and Luciano Serafini. \\ Deep Symbolic Learning: Discovering Symbols and Rules from Perception \\  
\emph{International Workshop on Neural-Symbolic Learning and Reasoning 2023}\\
\href{https://sites.google.com/view/nesy2023/home/nesy2023-programme-outline?authuser=0}{NeSy 2023} (\textbf{Accepted for spotlight presentation})\\ \\
\years{2022}\textbf{Sagar Malhotra} and Luciano Serafini\\
On Projectivity in Markov Logic Networks\\ 
\emph{International Workshop on Probabilistic Logic Programming 2022}\\ \href{https://easychair.org/publications/preprint/2lTk}{ PLP 2022}\\ \\
% \newpage
% \emph{R.i.C.e.R.c.A: RCRA Incontri E Confronti, AIxIA 2022.} \href{https://ricerca2022.wordpress.com}{ R.i.C.e.R.c.A 2022}\\  \\
% \newpage
\years{2021}\textbf{Sagar Malhotra} and Luciano Serafini. Weighted Model Counting in FO$^2$ with Cardinality Constraints and Counting Quantifiers: A Closed Form Formula\\ \emph{International Workshop on Statistical Relational AI, IJCLR 2021. }\\
\href{https://starai.cs.kuleuven.be/2021/}{ StarAI, IJCLR 2021} \\ \\ 
\years{{2020}}\textbf{Sagar Malhotra} and Luciano Serafini. Weighted Model Counting in C$^2$ (Abstract) \\
\emph{Workshop on Machine Learning and Data Mining, AIxIA 2020}\\
 \href{https://sites.google.com/view/mldm2020-workshop/program?authuser=0}{MLDM 2020}

%\newpage
% \section*{Under Review and Preprints}
% \years{2024}Floriann Chen,  Felix Weitkämper and \textbf{Sagar Malhotra}\\
% Understanding Domain-Size Generalization in Markov Logic Networks\\
% \emph{Under Review}\\
\section*{Preprints\footnote[1]{Supervised students coauthors are underlined}}
\years{2025}\underline{Peter Blohm}, Patrick Indri, Thomas Gärtner, \textbf{Sagar Malhotra}\\ 
Probably Approximately Global Robustness Certification\\
\href{https://countinglogic.github.io/files/Preprint.pdf}{Link} \\ \\  
\years{2025} Steve Azzolin$^{*}$, \textbf{Sagar Malhotra}$^{*}$, Andrea Passerini, Stefano Teso\\
Beyond Topological Self-Explainable GNNs: A Formal Explainability Perspective\\
$^*$Equal Contribution. \href{https://arxiv.org/abs/2502.02719}{Arxiv}\\ 

\years{2024} \underline{Davide Bizzaro}, Luciano Serafini and \textbf{Sagar Malhotra}\\
Towards Counting Markov Equivalence Classes with Logical Constraints\\
% \emph{Results from co-supervising Master's thesis of Davide Bizzaro}\\
\href{https://arxiv.org/abs/2405.13736}{Arxiv} 

% I can use the same footnote\footnotemark{} more than 
% once\footnotemark[\value{footnote}].
% \footnotetext{Supervised student collaborator.}

% \years{2023}\textbf{Sagar Malhotra}, Davide Bizzaro and Luciano Serafini\\
% Lifted Inference beyond First Order Logic\\
% \emph{Under Review at Artificial Intelligence Journal}\href{https://arxiv.org/abs/2302.09830}{\  arXiv:2302.09830}\\

% \years{2023}\textbf{Sagar Malhotra} and Luciano Serafini.\\
% Weighted First Order Model Counting with Directed Acyclic Graph Axiom\\
% \href{https://arxiv.org/abs/2302.09830}{arXiv:2302.09830}


% \section*{Ongoing Collaborations}
% \noindent

% Cooperative Artificial Intelligence \\
% Collaborators: Bruno Lepri (FBK, Italy), Luciano Serafini (FBK, Italy)\\ 

% Graphon Estimation and Inference for Relational Structures\\
% Collaborators: Manfred Jaeger (Aalborg University, Denmark), Luciano Serafini (FBK, Italy) 


% My research revolves around formal analysis of probability distributions over relational structures. I am especially interested in:

% $\cdot$ Random graph models and their extension to more complex relational domains\\
% $\cdot$ Exact and approximate probabilistic inference  \\
% $\cdot$ Combinatorics over relational structures\\ 
% $\cdot$ Consistency of probabilistic inference\\
% $\cdot$ Estimating asymptotic properties from sub-sampled relational structures\\

\section*{Talks and Tutorials}
% \noindent
\years{2024} Fundamental Problems in Statistical Relational AI\\
\href{https://countinglogic.github.io/StarAI-KR2024.github.io/}{Tutorial} at \href{https://kr.org/KR2024/workshops_tutorials.php}{KR 2024}\\
\years{2022}On Consistency of Learning and Inference in Statistical Relational Learning \\
\emph{Invited Talk at MLDM Workshop at the AIxIA Conference 2022, Udine, Italy }\href{https://sites.google.com/view/mldm2022/program?authuser=0}{ (Abstract)}\\ \\
\years{2022}On Probabilistic Inference in Logical Domains\\
\emph{Invited talk at the Institute of Informatics, Ludwig Maximilian University of Munich, Germany}\\  \\
\years{2022}A Tutorial on Probabilistic Inference in Logical Domains\\ \emph{Guest Lecture at the Knowledge representation and Learning course, University of Padova, Italy}\\ \\
\years{2022}Weighted First-Order Model Counting \\
\emph{DocInProgress Colloquium, Department of Mathematics, University of Trento, Italy} \\ \\ 
\years{2022}Weighted First-Order Model Counting\\
\emph{AAAI 2022@FBK Workshop, Trento, Italy  }\href{https://www.youtube.com/watch?v=2TRXEdq-NZg&t=3937s}{(Video)}

%%\hrule
% \section*{Programming Skills}
% \noindent 
% Fluent: Python, Pandas, \LaTeX\\
% Familiar: Mathematica, R, Pytorch, HTML



\section*{Reviewing and PC Experience}
Session Chair at ECML 2024, Session Chair at KR 2024, Reviewer ICLR 2024, PC member AAAI 2024, Reviewer NeurIPS 2024, Reviewer KR 2024, PC Member IJCAI 2024, PC Member PLP workshop 2024, Reviewer ICLR 2024, Reviewer AISTATS 2024, PC Member AAAI 2024, PC Member SAC 2024, Reviewer NeurIPS 2023, PC Member MLG Workshop-ECML 2023,PC Member PLP workshop 2023, PC Member  KR 2023, PC Member  AAAI 2023, Reviewer  AISTATS 2023, Sub-Reviewer  KR 2021, Reviewer for  Data Mining and Knowledge Discovery (Q1 Journal)


\section*{Master's Student Supervision}
\years{2024} Peter Blohm,  TU Wien, Austria\\
Thesis title (tentative): Practical PAC-Verification with Signal Temporal Logic \\ 

\years{2023} Davide Bizzaro,  University of Padova, Italy\\
Thesis: Lifted Inference Beyond First Order Logic 

\section*{Other Important Student Supervision Roles}
    \years{2024} Florian Chen, TU Wien, Austria\\
    (Partially supervised in a student internship,\\ leading to a conference publication at ECML PKDD 2024)\\

    \years{2024} Alexander Pluska,  TU Wien, Austria\\ 
    (Supervised in a graduate course,\\ leading to a conference publication ar KR 2024)\\

\section*{Teaching Experience}

\years{2024-Now} \textbf{Modern Applications of Logic in Machine Learning}\\ (Elective graduate course in Computer Science, dean's approval awaited)\\ 
% \textbf{Experience:} I have developed a new syllabus for graduates students interested in logic and machine learning. The course will consist of four inter-dependent sections: 
% \begin{itemize}
    % \item \textbf{Statistical relational learning}: models that integrate logic, probability and learning e.g., Markov logic, Problog etc. 
    % \item \textbf{Algorithms}: ML relevant algorithmic problems in logic such as weighted model counting and MaxSAT 
    % \item \textbf{Neuro-symbolic integration:} models that integrate reasoning and learning in neural networks
    % \item \textbf{Theoretical Foundations:}role of logic in learning theory and expressivity analysis of ML models like graph neural networks and transformers
% \end{itemize}




\years{2023 - Now} \textbf{Introduction to Machine Learning} (Bachelor's in Computer Science)\\
% \textbf{Experience:} I was part of the team that developed the first edition of this course in 2023. My key role was developing the module and exercises on Probabilistic Machine Learning. I also taught the lectures for Probabilistic Machine Learning and was responsible for the office hours for various modules of the course. I developed automatically graded python based exercises that gave students hands-on experience. I also designed a large question bank for the theoretical exam. \\

\years{2023 - Now} \textbf{Machine Learning Algorithms and Applications}
 (Master's in Computer Science)\\
%  This is a project based course organized by the Machine Learning Research Unit. I have consistently offered new projects in this course. One of the offered course led to a publication with a student Alexander Pluska at the \emph{International Conference on Principles of Knowledge Representation and Reasoning 2024}. \\ \\ 
 
 \years{2023 - Now} \textbf{Theoretical Foundations and Research Topics in Machine Learning}\\
 (Master's in Computer Science)\\
%  I conduct many of the exercise and course-work sessions on PAC learning and graph neural networks.

% \section*{Awards and Achievements}
% \years{2018}Bronze medal in TrackML particle tracking challenge on Kaggle.\\
% \years{2017} Part of the winning team in Industrial Problem Solving using Physics (\href{https://www.unitn.it/archivio/events/ipsp2017.html}{IPSP 2017})\\
% \years{2017}Awarded fully funded trip to Innovation Days-Innsbruck in StartUp Lab, Trento\\
% \years{2016}Awarded full Scholarship for the Joint Masters in Theoretical Physics at University of Trento and SISSA- Trieste (Declined)\\
% \years{2016}Awarded Opera Universitaria Scholarship for Masters in Physics at University of Trento\\
% \years{2016}Amongst top 5$\%$ candidates in the Joint Entrance Screening Test- Physics 2016 among $\sim$ 5000 candidates\\
% \years{2016}Amongst top 5 $\%$ candidates in IIT Joint Admission Test for Masters in Physics  2016 among $\sim$ 10000 candidates

% \newpage 

% \section*{References}
% Prof. Luciano Serafini \\
% Head of Unit\\
% Data and Knowledge Management Group\\
% Fondazione Bruno Kessler, Trento, Italy\\
% Email: \href{mailto: serafini@fbk.eu}{serafini@fbk.eu} \\ 

% Prof. Manfred Jaeger \\
% Aalborg University, Aalborg, Denmark \\ 
% Email: \href{mailto: jaeger@cs.aau.dk}{jaeger@cs.aau.dk} \\ 

% Dr. Felix Weitkämper \\
% Institute of Informatics, LMU, Munich, Germany \\
% Email: \href{mailto: felix.weitkaemper@lmu.de}{felix.weitkaemper@lmu.de} \\ \\ 


% \vfill{}


% \begin{center}
% {\scriptsize  Last updated: \today\- •\- 
% \href{https://countinglogic.github.io/research/CV/CV.pdf}{For latest version click here. }}
% \end{center}

\end{document}