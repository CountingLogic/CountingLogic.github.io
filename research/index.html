<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">

<html>
	<head>
		<link href="../letter_style.css" rel="stylesheet" type="text/css">

		
	
		
<!-- Access to MathJax through their server !-->

<script type="text/javascript" charset="utf-8" 
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,
https://vincenttam.github.io/javascripts/MathJaxLocal.js"></script>

	</head>

<body>
<cite><a href="../index.html">Sagar</a></cite>

<div class="text">
	<div class="left">
		<h1 style="font-weight: normal;"> Research</h1>

			<BLOCKQUOTE><center><em>
				â€œGood work is not done by "humble" men.<BR>
				A man who is always asking "Is what I do worth while?" <BR>
				"Am I the right person to do it?" will always be ineffective <BR>
				He must shut his eyes a little <BR>
				think a little more of his subject and himself than they deserve"<BR><BR>
					-- G.H Hardy. A Mathematician's Apology 
				</em></center></BLOCKQUOTE>

		<h2 style="font-weight: normal;"> Research Interests</h2>
		<P><b>Tractable Probabilistic Inference in Relational Domains</b> <BR>
			I am interested in probabilistic models over relational structures. I have worked in settings, where the relational structures are defined in a first-order language. In such a setting, 
			the probabilistic inference task reduces to <a href = "https://arxiv.org/abs/1412.1505">weighted model counting </a>of a first-order logic formula. This
			is intractable in general. Hence, my work has focused on identifying tractable fragments of first order logic, where model counting can be performed in polynomial time. I am particularly interested in analytical approaches to weighted model counting</a>, which yield <a href = "https://arxiv.org/abs/2110.05992">closed form formulae for model counting. </a>
		</P>
		<P> <b>Consistent Probabilistic Inference in Relational Domains</b><BR> 
			Recently, I have been interested in consistency of probabilistic inference. The <a href="https://arxiv.org/abs/1111.3054" >problem</a> originates from the works of Shalizi and Rinaldo in Exponential Random Graphs Models (ERGMs). And was generalized to probabilistic logic setting by <a href = https://arxiv.org/abs/1807.00564> Jaeger and Schulte</a>. I with Luciano Serafini, have recently been able to get some <a href = "https://arxiv.org/abs/2204.04009">results</a> on this problem with respect to Markov Logic Networks. 
		</P>
		
		<P>
			<b>Future Interests</b><BR>
				These are the topics I have dabbled in but could not make headway. I hope to go back to (at least some of) them soon: Approximate Weighted Model Counting with guarantees, a  minimum description length based approach to probabilistic inductive logic programming akin to <a href ="https://www.ijcai.org/proceedings/2021/0358.pdf">this</a> and defining the notion of <a href= https://en.wikipedia.org/wiki/Graphon>Graphon</a> and estimating it in the probabilistic logic setting.
		</P>
		<h2 style="font-weight: normal;"> Conference Publications</h2>
		<P><b>Sagar Malhotra</b> and Luciano Serafini. Weighted Model Counting in FO$^2$ with Cardinality Constraints and Counting Quantifiers: A Closed Form Formula.<BR>
			<i>Accepted for <b>Oral</b> presentation at the $36^{th}$ AAAI Conference on Artificial Intelligence, 2022. <BR>
			Arxiv <a href = "https://arxiv.org/abs/2110.05992">Link </a>  to the full paper with appendix<BR>
			Conference <a href = "https://aaai-2022.virtualchair.net/poster_aaai2663">page</a> with a short video and paper<BR>
			Proceedings are yet to appear.</i>
		</P>
		
		<P><b>Sagar Malhotra</b> and Luciano Serafini. A Combinatorial Approach to Weighted Model Counting in the Two Variable Fragment with Cardinality Constraints.<BR>
		<i>Proceedings of the $20^{th}$ International Conference of the Italian Association for Artificial Intelligence, 2021<BR>
		<a href = "https://underline.io/lecture/42130-a-combinatorial-approach-to-weighted-model-counting-in-the-two-variable-fragment-with-cardinality-constraints">Full Presentation Video</a> <BR>
		Proceedings are yet to appear.	
		</i>	
		</P>

		
		
		<h2 style="font-weight: normal;">Workshop Publications</h2>
		<b>Sagar Malhotra</b> and Luciano Serafini. Weighted Model Counting in FO$^2$ with Cardinality Constraints and Counting Quantifiers: A Closed Form Formula.<BR>
		 <i>$10^{th}$ International Workshop on Statistical Relational AI, 2021</i><a href = "https://starai.cs.kuleuven.be/2021/"> Link</a>
		
		 <h2 style="font-weight: normal;">Submitted and Preprint Publications</h2>
		<b>Sagar Malhotra</b> and Luciano Serafini. On Projectivity in Markov Logic Networks<BR>
		<i>Under Review. </i><a href = "https://arxiv.org/abs/2204.04009">Preprint</a> 

		<p>$a=b$</p>
		
		
		</div>
		</div>
	<!-- The stuff I am yet to do<BR> -->
	<!-- And you may ask yourself<BR> -->
	


	<!-- <p class="p2"><span class="s1"><i>Space for documenting the stuff I have done,</i></span></p> -->
    <!-- <p class="p2"><span class="s1"><i>the stuff I am yet to do</i></span></p> -->
	<!-- <p class="p2"><span class="s1"><i>and the stuff I hope is presently beyond my imagination !</i></span></p> -->

	<!-- <p class="p2"><span class="s1"><i>Genius is Patience - Isaac Newton</i></span></p> -->
    <!-- <p class="p2"><span class="s1"><i>'Obvious' is the most dangerous word in mathematics - E.T. Bell</i></span></p> -->


<!-- <P>I work on methods for building predictive models from data generated by -->
<!-- stochastic processes, and applying those models to questions about neural -->
<!-- information processing, self-organization in cellular automata, and so forth. -->
<!-- All of this is about using tools from probability, statistics, and machine -->
<!-- learning to understand large, complex, nonlinear dynamical systems.  This is -->
<!-- why my dissertation was in statistical physics, but I now teach in a statistics -->
<!-- department. -->

<!-- <P>My <a href="http://www.stat.cmu.edu/~cshalizi/">departmental homepage</a> -->
<!-- has a fuller explanation of what I do, and how I came to do it, in terms which -->
<!-- (I hope) make sense to statisticians. -->

<!-- <center> -->
	<!-- [<a href="#summaries">Summaries</a>] &nbsp; -->
	<!-- [<a href="#talks">Talks and Presentations</a>] &nbsp; -->
	<!-- [<a href="#papers">Papers and Book Chapters</a>] &nbsp; -->
	<!-- [<a href="../teaching/index.html">Lecture Notes</a>] -->
<!-- </center> -->


<!-- <h2><a name="summaries">Summaries</a></h2> -->

<!-- <P><a href="cv.pdf">Curriculum Vitae/Resume</a>: Lists my publications, talks -->
<!-- given, and other professional data.</P> -->

<!-- <P>My doctoral dissertation, <cite><a href="../thesis/index.html">Causal Architecture, -->
<!-- Complexity and Self-Organization in Time Series and Cellular -->
<!-- Automata</a></cite> (2001).  A unified presentation of the material from my -->
<!-- previous papers on computational mechanics, plus several chapters of until-then -->
<!-- unpublished work.  Includes quantitative definitions of "emergence" and -->
<!-- "self-organization", of which I am fairly fond.</P> -->


<!-- <h2><a name="papers">Papers and Book Chapters</a></h2> -->

<!-- In order of completion.  Lecture notes are on -->
<!-- my <a href="../teaching/index.html">teaching</a> page.</P> -->

<!-- <P>[1] <a href="http://www.santafe.edu/~chaos/">Jim Crutchfield</a> &amp; CRS, -->
<!-- "Thermodynamic Depth of Causal States: Objective Complexity via Minimal -->
<!-- Representation", <cite>Physical Review E</cite> <strong>59</strong> (1999): -->
<!-- 275--283 (<a href="TDCS.pdf">PDF</a>), <a href="http://arxiv.org/abs/cond-mat/9808147">cond-mat/9808147</a>.  It -->
<!-- explains why thermodynamic depth, a notion advanced by the late, great Heinz -->
<!-- Pagels, while nifty in concept and certainly not just Yet Another Complexity -->
<!-- Measure, doesn't work very well as originally proposed, and what needs to be -->
<!-- changed to make it work, namely adding causal states.  (In the words of the -->
<!-- poet, "we subsume what we do not obliterate.")</P> -->

<!-- <P>[2] <a href="http://www.santafe.edu/~moore/">Cris Moore</a>, Mats Nordahl, <a -->
<!-- href="http://xenia.media.mit.edu/~nelson/">Nelson Minar</a> &amp; CRS, -->
<!-- "Entropic Coulomb Forces in Ising and Potts Antiferromagnets and Ice -->
<!-- Models," <a href="http://arxiv.org/abs/cond-mat/9902200">cond-mat/9902200</a>; -->
<!-- final published version, "Vortex Dynamics and Entropic Forces in -->
<!-- Antiferromagnets and Antiferromagnetic Potts Models," <cite>Physical Review -->
<!-- E</cite> <strong>60</strong> (1999): 5344--5351. (To be honest, I didn't write -->
<!-- any of this, but did a large chunk of the simulation work.)  Only of interest -->
<!-- to people who care about pretty abstract models in statistical mechanics.</P> -->

<!-- <P>[3] Jim Crutchfield, <a href="http://hornacek.coa.edu/dave/">Dave Feldman</a> -->
<!-- &amp; CRS, "Comment on 'Simple Measure for Complexity,' " <a -->
<!-- href="http://arxiv.org/abs/chao-dyn/9907001">chao-dyn/9907001</a> = -->
<!-- <cite>Physical Review E</cite> <strong>62</strong> (2000): 2996--2997.  Short, -->
<!-- critical remarks on Yet Another Complexity Measure.</P> -->

<!-- <P>[4] CRS &amp; Jim Crutchfield, <a name="cmppss">"Computational -->
<!-- Mechanics: Pattern and Prediction, Structure and Simplicity," <cite>Journal of -->
<!-- Statistical Physics</cite> <strong>104</strong> (2001): 816--879</a> (<a -->
<!-- href="cmppss.pdf">PDF</a>), <a -->
<!-- href="http://arxiv.org/abs/cond-mat/9907176">cond-mat/9907176</a>.  I'll let -->
<!-- <cite>Mathematical Reviews</cite> describe this one for me: <blockquote>The -->
<!-- main concern of this article, written in a very general setting, is how to -->
<!-- maximally compress the past of a random process still keeping all the useful -->
<!-- information, so as to predict its future as well as if all the past were -->
<!-- remembered. In this connection the authors introduce "causal states" into which -->
<!-- all the space of possible past histories is cut. Within each causal state all -->
<!-- the individual histories have one and the same conditional distribution for -->
<!-- future observables. An epsilon-machine is defined which uses the causal states -->
<!-- for prediction. The authors prove several theorems about them, whose intuitive -->
<!-- meaning is natural: that causal states are maximally prescient, that they have -->
<!-- the minimal statistical complexity among all prescient rivals, that they are -->
<!-- unique, that epsilon-machines have the minimal entropy among all the prescient -->
<!-- rivals and some inequalities. This voluminous article, containing 140 -->
<!-- references, may also be used as a survey in the area of abstract theory of -->
<!-- computational complexity of prediction.</blockquote></P> -->

<!-- <P>[5] CRS &amp; <a href="http://www.williamtozier.com/">Bill -->
<!-- Tozier</a>, "A Simple Model of the Evolution of Simple Models of -->
<!-- Evolution," <a -->
<!-- href="http://arxiv.org/abs/adap-org/9910002">adap-org/9910002</a>; accepted by -->
<!-- <cite><a href="http://www.santafe.edu/~moore/jwas.html">JWAS</a></cite>; -->
<!-- rejected by <cite>Theoretical Population Biology</cite> for lack of decorum.  A -->
<!-- not <em>entirely</em> unserious critique of recent attempts to model evolution -->
<!-- by physicists who don't know biology.</P> -->

<!-- <P>[6] CRS &amp; Jim Crutchfield, "Pattern Discovery and Computational -->
<!-- Mechanics," <a href="http://arxiv.org/abs/cs.LG/0001027">cs.LG/0001027</a>. -->
<!-- Why people who are interested in machine learning should care about what we do. -->
<!-- Amicably rejected by the <cite>Proceedings</cite> of the 17th International -->
<!-- Conference on Machine Learning, with remarks on the order of "interesting, but -->
<!-- you really need to say more about how to code it up," which was fair enough, -->
<!-- and provided some of the impetus for "An Algorithm for Pattern Discovery" and -->
<!-- "Blind Construction" (below).</P> -->

<!-- <P>[7] CRS &amp; Jim Crutchfield, "Information Bottlenecks, Causal -->
<!-- States, and Statistical Relevance Bases: How to Represent Relevant Information -->
<!-- in Memoryless Transduction," <a -->
<!-- href="http://arxiv.org/abs/nlin.AO/0006025">nlin.AO/0006025</a>.  Discussion of -->
<!-- several related ways of extracting the information one variable contains about -->
<!-- another, and using it to model the functional relationship or transducer -->
<!-- connecting the two.  <cite>Advances in Complex Systems</cite> -->
<!-- <strong>5</strong> (2002): 91--95.</P> -->

<!-- <P>[8] <a href="http://www.santafe.edu/~wim/">Wim Hordijk</a>, CRS &amp; -->
<!-- Jim Crutchfield, "Upper Bound on the Products of Particle Interactions in -->
<!-- Cellular -->
<!-- Automata",  <cite>Physica D</cite> <strong>154</strong> (2001): 240--258, <a href="http://arxiv.org/abs/nlin.CG/0008038">nlin.CG/0008038</a>.  A proof of a -->
<!-- limit on how complicated the interactions between propagating emergent -->
<!-- structures in (one-dimensional) CAs can get.  Wim is too modest to call it -->
<!-- Hordijk's Rule, so I will.</P> -->

<!-- <P>[9] CRS and <a href="http://www.santafe.edu/~albers/">Dave -->
<!-- Albers</a>, "Symbolic Dynamics for Discrete Adaptive -->
<!-- Games," <a href="http://arxiv.org/abs/cond-mat/0207407">cond-mat/0207407</a>, -->
<!-- SFI Working Paper 02-07-031.  Why the hyper-stylized game-theory models which -->
<!-- have taken over econophysics in the last few years are <em>not</em> complex, -->
<!-- dynamically or statistically.  (We were going to call it "no chaos and little -->
<!-- complexity in the minority game," but settled on something more neutral.) -->
<!-- Which isn't to say they're not worth studying; just that they need to justify -->
<!-- themselves by what they can tell us about real(er) systems.  Submitted to -->
<!-- <citE>Physics Letters A.</cite> (Update, 2003: Revised to placate an unusually -->
<!-- appalling referee.)</P> -->

<!-- <P>[10] CRS, Kristina L. Klinkner and Jim Crutchfield, "An Algorithm for Pattern -->
<!-- Discovery in Time -->
<!-- Series," <a href="http://arxiv.org/abs/cs.LG/0210025">cs.LG/0210025</a>.  (This -->
<!-- version supersedes the SFI Working Paper one.)  A statistically reliable, -->
<!-- linear-time algorithm for inferring causal states from data.  The code and -->
<!-- documentation are <a href="../CSSR/index.html">available</a>, released under the -->
<!-- <a href="http://www.gnu.org/">Gnu</a> <a -->
<!-- href="http://www.gnu.org/copyleft/gpl.html">Public License</a>.  I'd recommend -->
<!-- reading the "Blind Construction" paper first, since I think that has a clearer -->
<!-- presentation of the algorithm and its motivation.</P> -->

<!-- <P>[11] CRS and <a href="http://www.santafe.edu/~moore/">Cris -->
<!-- Moore</a>, "What Is a Macrostate?  Subjective Measurements and Objective -->
<!-- Dynamics," <a href="http://arxiv.org/abs/cond-mat/0303625">cond-mat/0303625</a>; -->
<!-- also <a -->
<!-- href="http://philsci-archive.pitt.edu/archive/00001119/">PITT-PHIL-SCI-1119</a> -->
<!-- at the <a href="http://philsci-archive.pitt.edu/">Phil-Sci Archive</a>.  Why -->
<!-- thermodynamic macrostates are neither completely objective nor (as some argue) -->
<!-- completely epistemic, but are instead causal states, in the sense of -->
<!-- computational mechanics.  Submitted to <cite>Studies in the History and -->
<!-- Philosophy of Modern Physics.</cite></P> -->

<!-- <P>[12] CRS and Kristina L. -->
<!-- Klinkner, "<a name="quant-self-org-in-FN03">Quantifying Self-Organization in -->
<!-- Cyclic Cellular Automata</a>," pp. 108--117 in Lutz Schimansky-Geier, Derek -->
<!-- Abbott, Alexander Neiman and Christian Van den Broeck (eds.), <cite>Noise in -->
<!-- Complex Systems and Stochastic Dynamics</cite> (Bellingham, Washington: SPIE, -->
<!-- 2003), part of the proceedings of <a -->
<!-- href="http://spie.org/Conferences/programs/03/fn/">Fluctuations and Noise -->
<!-- 2003</a>.  A preliminary report on the work that became "Quantifying -->
<!-- Self-Organization with Optimal Predictors", below, which however has more -->
<!-- details on the algorithm and related literature, because we were less -->
<!-- space-constrained.  <a -->
<!-- href="http://arxiv.org/abs/nlin.AO/0507067">nlin.AO/0507067</a>. -->

<!-- <P>[13] "Optimal Nonlinear Prediction of Random Fields on Networks," for the -->
<!-- conference <a href="http://www.ens-lyon.fr/~ethierry/DMCS/">Discrete Models for -->
<!-- Complex Systems 2003</a>, printed -->
<!-- in <cite><a href="http://dmtcs.loria.fr/">Discrete Mathematics and Theoretical -->
<!-- Computer Science</a></cite>, <strong>AB(DMCS)</strong> (2003): 11--30. -->
<!-- Available online from either -->
<!-- the <a -->
<!-- href="http://dmtcs.loria.fr/proceedings/html/dmAB0102.abs.html">journal</a> or -->
<!-- arxiv.org -->
<!-- (<a href="http://arxiv.org/abs/math.PR/0305160">math.PR/0305160</a>).</P> -->

<!-- <P>[14] "Methods and Techniques of Complex Systems Science: An Overview", -->
<!-- chapter 1 (pp. 33--114) in Thomas S. Deisboeck and J. Yasha Kresh -->
<!-- (eds.), <cite>Complex Systems Science in Biomedicine</cite> (NY: Springer, -->
<!-- 2006), <a href="http://arxiv.org/abs/nlin.AO/0307015">nlin.AO/0307015</a>.  A -->
<!-- summary of the tools people <em>should</em> use to study complex systems, -->
<!-- covering statistical learning and data-mining, time series analysis, cellular -->
<!-- automata, agent-based models, evaluation techniques and simulation, information -->
<!-- theory and complexity measures, with 288 references (a personal record).</P> -->

<!-- <P>[15] CRS and Kristina L. Klinkner, "Blind Construction of Optimal Nonlinear -->
<!-- Recursive Predictors for Discrete Sequences", pp. 504--511 in Max Chickering -->
<!-- and Joseph Halpern (eds.), <cite>Uncertainty in Artificial Intelligence: -->
<!-- Proceedings of the Twentieth -->
<!-- Conference</cite>, <a href="http://arxiv.org/abs/cs.LG/0406011">cs.LG/0406011</a> -->
<!-- (Arlington, Virginia: AUAI Press, 2004).  An eight-page paper -->
<!-- on <a href="../CSSR/index.html">CSSR</a>, including experimental comparison to the -->
<!-- standard heuristic of fitting hidden Markov models via the EM algorithm, and -->
<!-- selecting among them with cross-validation.  (We're better.)  I think this is -->
<!-- the clearest description yet of the algorithm, though proofs were omitted to -->
<!-- save space.</P> -->

<!-- <P>[16] CRS, Kristina L. Klinkner and <a href="http://robhaslinger.org/">Rob -->
<!-- Haslinger</a>, "Quantifying Self-Organization with Optimal -->
<!-- Predictors", <cite>Physical Review Letters</cite> <strong>93</strong> (2004): -->
<!-- 118701, <a href="http://arxiv.org/abs/nlin.AO/0409024">nlin.AO/0409024</a>. -->
<!-- Why self-organization should be identified with increasing complexity over -->
<!-- time, and how to measure that complexity by measuring the amount of information -->
<!-- needed for optimal prediction.  This is the experiment I said I was going to do -->
<!-- at the end of "Is the Primordial Soup Done Yet?", after only eight years.  But -->
<!-- one of those years we spent waiting for the referees to see the light, so it -->
<!-- doesn't count.  With neat color pictures!</P> -->

<!-- <P>[17] "The Backwards Arrow of Time of the Coherently Bayesian Statistical -->
<!-- Mechanic", <a href="http://arxiv.org/abs/cond-mat/0410063">cond-mat/0410063</a>. -->
<!-- Why we should <em>not</em> identify thermodynamic entropy with uncertainty -->
<!-- (Shannon entropy) in a distribution over microstates.  Doing so, in combination -->
<!-- with the ordinary laws of motion and Bayesian probability updating, shows that -->
<!-- entropy is non-increasing.  Replacing Bayesian updating with repeated entropy -->
<!-- maximization is bad statistics, and actually makes things worse. -->

<!-- <P>[18] <a href="http://www-personal.umich.edu/~mgastner/">Michael -->
<!-- T. Gastner</a>, CRS and <a -->
<!-- href="http://www-personal.umich.edu/~mejn/">M. E. J. "Mark" Newman</a>, -->
<!-- "Maps and cartograms of the 2004 US presidential election -->
<!-- results", <cite>Advances in Complex Systems</cite>, <strong>8</strong> (2005): -->
<!-- 117--123 [<a href="../../www-personal.umich.edu/_mejn/papers/election.pdf">PDF -->
<!-- preprint</a>, <a href="../election/index.html">web page</a>].  The only work I have ever -->
<!-- done, or likely will do, which generated hate mail. -->

<!-- <P>[19] Kristina L. Klinkner, CRS -->
<!-- and <a href="http://physics.usfca.edu/marcelo/">Marcelo Camperi</a>, "Measuring -->
<!-- Shared Information and Coordinated Activity in Neuronal Networks", pp. 667--674 -->
<!-- in Yair Weiss, Bernhard Sch&ouml;lkopf and John C. Platt (eds.), <cite>Advances -->
<!-- in Neural Information Processing Systems 18</cite> (MIT Press, 2006), -->
<!-- a.k.a. <a href="http://www.nips.cc/Conferences/2005/">NIPS -->
<!-- 2005</a>, <a href="http://arxiv.org/abs/q-bio.NC/0506009">q-bio.NC/0506009</a>. -->
<!-- The best way to measure those things is to look at the mutual information -->
<!-- between the causal states of the different neurons, suitably normalized: this -->
<!-- handles nonlinear, stochastic relationships between extended patterns of -->
<!-- behavior without any fuss or issues, and extends naturally to truly global -->
<!-- measures of coordination, not just pairwise averages.  (Plus, we can find the -->
<!-- causal states with <a href="../CSSR/index.html">CSSR</a>.)  Because -->
<!-- practice is the sole criterion of truth, we also show that this "informational -->
<!-- coherence" works <em>very nicely</em> on a model of beta and gamma rhythms, -->
<!-- where standard approaches get confused. -->
<!-- (<a href="../weblog/356.html">More</a>.) -->

<!-- <P>[20] <a href="http://www.berrymanconsulting.com/">Matthew J. Berryman</a>, -->
<!-- Scott W. Coussens, Yvonne Pamula, Declan Kennedy, Kurt Lushington, CRS, Andrew -->
<!-- Allison, A. James Martin, David Saint -->
<!-- and <a href="http://www.eleceng.adelaide.edu.au/Personal/dabbott/">Derek -->
<!-- Abbott</a>, "Nonlinear Aspects of the EEG During Sleep in Children", pp. 40--48 -->
<!-- in Nigel G. Stocks, Derek Abbott and Robert P.  Morse -->
<!-- (eds.), <cite>Fluctuations and Noise in Biological, Biophysical, and Biomedical -->
<!-- Systems III</cite> (Bellingham, Washington: SPIE, -->
<!-- 2005), <a href="http://arxiv.org/abs/q-bio.NC/0506015">q-bio.NC/0506015</a>. -->

<!-- <P>[21] "Functionalism, Emergence, and Collective Coordinates", -->
<!-- <a href="http://dx.doi.org/10.1017/S0140525X04310149"><cite>Behavioral and -->
<!-- Brain Sciences</cite> <strong>27</strong> (2004): 635--636</a>.  This is part -->
<!-- of the peer commentary (pp. 627--637, same issue) on Don Ross and David -->
<!-- Spurrett's "What to Say to a Skeptical Metaphysician: A Defense Manual for -->
<!-- Cognitive and Behavioral Scientists" (<a -->
<!-- href="http://dx.doi.org/10.1017/S0140525X04000147">pp. 603--627</a>), and is -->
<!-- followed by Ross and Spurrett's reply to comments (<a -->
<!-- href="http://dx.doi.org/10.1017/S0140525X04330141">pp. 637--647</a>). [<a -->
<!-- href="RSBBS.pdf">PDF</a>] -->

<!-- <P>[22] CRS, <a href="http://robhaslinger.org/">Rob -->
<!-- Haslinger</a>, <a href="http://perso.ens-lyon.fr/jean-baptiste.rouquier/">Jean-Baptiste -->
<!-- Rouquier</a>, Kristina L. Klinkner -->
<!-- and <a href="http://www.santafe.edu/~moore/">Cristopher Moore</a>, "Automatic -->
<!-- Filters for the Detection of Coherent Structure in Spatiotemporal -->
<!-- Systems", <cite>Physical Review E</cite> <strong>73</strong> (2006): -->
<!-- 036104, <a href="http://arxiv.org/abs/nlin.CG/0508001">nlin.CG/0508001</a>. -->
<!-- Two different filters --- one based on local perturbation, the other based on -->
<!-- statistical forecasting complexity --- which are both able to recover the known -->
<!-- coherent structures of various cellular automata, without using prior knowledge -->
<!-- of the rule or the structures.  See -->
<!-- the <a href="../weblog/375.html">auto-vulgarization</a> for more, but not so -->
<!-- much more as the paper.  (To meet the arxiv's requirements, we had to replace -->
<!-- our original figures with highly-compressed -->
<!-- jpegs.  <a href="AFICS.pdf">Here</a> is a PDF version with the original, -->
<!-- full-resolution figures; it is, oddly enough, more than a megabyte smaller than -->
<!-- the arxiv-generated PDF.) -->
<!-- The <a href="https://sourceforge.net/projects/cimula/">source code is -->
<!-- available</a>, in <a href="http://caml.inria.fr/">Objective Caml</a>. -->

<!-- <P>[23] CRS, Marcelo F. Camperi and Kristina L. Klinkner, -->
<!-- "Discovering Functional Communities in Dynamical -->
<!-- Networks", <a href="http://arxiv.org/abs/q-bio.NC/0609008">q-bio.NC/0609008</a> -->
<!-- = pp. 140--157 in <a href="http://www.cs.cmu.edu/~anya/">Anna -->
<!-- Goldenberg</a>, <a href="http://www.genomics.princeton.edu/~eairoldi/">Edo -->
<!-- Airoldi</a>, <a href="http://www.stat.cmu.edu/~fienberg/">Stephen -->
<!-- E. Fienberg</a>, <a href="http://www.cs.cmu.edu/~alicez/">Alice -->
<!-- Zheng</a>, <a href="http://www.cs.princeton.edu/~blei/">David M. Blei</a> and -->
<!-- <a href="http://www.cs.cmu.edu/~epxing/">Eric P. Xing</a> -->
<!-- (eds.), <cite>Statistical Network Analysis: Models, Issues and New -->
<!-- Directions</cite> (New York: Springer-Verlag, 2007), the -->
<!-- proceedings of the <a href="http://www.icml2006.org/">ICML 2006</a> workshop -->
<!-- of <a href="http://nlg.cs.cmu.edu/page_icml_in.html">the same name</a>.  How -->
<!-- the combination of informational coherence (see Klinkner <em>et al.</em> above) -->
<!-- and <a href="../notebooks/community-discovery.html">community discovery -->
<!-- algorithms</a> let you identify <em>functional</em> modules, rather than just -->
<!-- anatomical ones.  We just look at an example from computational neuroscience -->
<!-- here, but there is no intrinsic reason you couldn't do this for any kind of -->
<!-- network dynamical system. -->

<!-- <P>[24] "Maximum Likelihood Estimation for <em>q</em>-Exponential (Tsallis) -->
<!-- Distributions", <a -->
<!-- href="http://arxiv.org/abs/math.ST/0701854">math.ST/0701854</a>, submitted -->
<!-- to <cite>Physical Review E</cite>.  Tsallis's -->
<!-- <em>q</em>-exponential distributions are heavy-tailed distributions which are -->
<!-- related to the Pareto distributions (in fact, a special case of what some -->
<!-- people call a "type II generalized Pareto").  They've recently become a big -->
<!-- deal in statistical -->
<!-- physics --- <a href="../notebooks/tsallis.html">much too -->
<!-- big</a>, if you ask me.  But if you <em>do</em> want to use them with real -->
<!-- data, this is the right way to do it.  The paper is accompanied -->
<!-- by <a href="tsallis-MLE/index.html">free, open-source code</a>, written -->
<!-- in <a href="http://www.r-project.org/">R</a>, implementing the maximum -->
<!-- likelihood estimator and bootstrapped standard errors and confidence intervals. -->

<!-- <p>[25] <a href="http://www.santafe.edu/~aaronc/">Aaron Clauset</a>, CRS, -->
<!-- and <a href="http://www-personal.umich.edu/~mejn/">M. E. J. Newman</a>, -->
<!-- "Power-law distributions in empirical -->
<!-- data", <a href="http://arxiv.org/abs/0706.1062">arxiv:0706.1062</a>, -->
<!-- <a href="http://dx.doi.org/10.1137/070710111"><cite>SIAM -->
<!-- Review</cite> <strong>51</strong> (2009): 661--703</a>.  What power laws are -->
<!-- (not just sort of straight lines on log-log plots), how to estimate their -->
<!-- parameters from data (use maximum likelihood, not linear regression), and how -->
<!-- to tell if you have one (by actual hypothesis testing). -->
<!-- With <a href="http://www.santafe.edu/~aaronc/powerlaws/">accompanying code</a> -->
<!-- in R and Matlab.  (<a href="../weblog/491.html">More</a>.) -->

<!-- <P>[26] "Social Media as Windows on the Social Life of the Mind", -->
<!-- <a href="http://arxiv.org/abs/0710.4911">arxiv:0710.4911</a>, to appear in -->
<!-- the <a href="http://www.isi.edu/~lerman/sss07/">AAAI spring 2008 symposium on -->
<!-- social information processing</a>.  A programmatic paper, pulling together some -->
<!-- ideas about <a href="../notebooks/neutral-cultural-networks.html">cultural -->
<!-- diffusion in networks</a> -->
<!-- and <a href="../notebooks/collective-cognition.html">collective cognition</a>, -->
<!-- and how those topics might be studied with data from user-driven Web sites. -->

<!-- <P>[27] <a href="http://robhaslinger.org/">Rob Haslinger</a>, Kristina -->
<!-- L. Klinkner and CRS, "The Computational Structure of Spike -->
<!-- Trains", <a href="http://dx.doi.org/10.1162/neco.2009.12-07-678"><cite>Neural -->
<!-- Computation</cite> <strong>22</strong> (2010): -->
<!-- 121--157</a>, <a href="http://arxiv.org/abs/1001.0036">arxiv:1001.0036</a>. -->
<!-- Applying <a href="../CSSR/index.html">CSSR</a> to real neural spike trains -->
<!-- to recover their computatinal structure and statistical complexity, and detect -->
<!-- the influence of external stimuli. -->

<!-- <P>[28] "Dynamics of Bayesian Updating with Dependent Data and Misspecified -->
<!-- Models", -->
<!-- <a href="http://dx.doi.org/10.1214/09-EJS485"><cite>Electronic Journal of -->
<!-- Statistics</cite> <strong>3</strong> (2009): -->
<!-- 1039--1074</a>, <a href="http://arxiv.org/abs/0901.1342">arxiv:0901.1342</a>. -->
<!-- What happens when all of your models are wrong, but you use Bayesian updating -->
<!-- to weight them anyway?  Answer: a process of natural selection, in which -->
<!-- fitness is proportional to likelihood.  This actually converges on the models -->
<!-- with the smallest relative entropy rate, if your prior distribution is smart -->
<!-- enough to respect a sieve (but then non-parametric non-Bayesian methods work -->
<!-- too).  (<a href="../weblog/601.html">More</a>.) -->

<!-- <P>[29] Shinsuke Koyama, <a href="http://www.cs.cmu.edu/~lcastell/">Lucia -->
<!-- Castellanos P&eacute;rez-Bolde</a>, CRS -->
<!-- and <a href="http://www.stat.cmu.edu/~kass/">Robert E. Kass</a>, "Approximate -->
<!-- Methods for State-Space -->
<!-- Models", <a href="http://dx.doi.org/10.1198/jasa.2009.tm08326"><cite>Journal of -->
<!-- the American Statistical Association</cite> <strong>105</strong> (2010): -->
<!-- 170--180</a>, <a href="http://arxiv.org/abs/1004.3476">arxiv:1004.3476</a>. -->
<!-- When modeling an observed time series as a noisy function of a hidden Markov -->
<!-- process, you need to estimate the state.  This is called "filtering", and doing -->
<!-- it exactly involves some generally-intractable integrals.  We approximate those -->
<!-- integrals via Laplace's method, giving us a "Laplace-Gaussian filter".  This is -->
<!-- surprisingly fast, accurate, and stable over time, and works well in a neural -->
<!-- decoding example. -->

<!-- <P>[30] CRS and <a href="http://acthomas.ca/">Andrew C. Thomas</a>, "Homophily -->
<!-- and Contagion Are Generically Confounded in Observational Social Network -->
<!-- Studies", <a href="http://dx.doi.org/10.1177/0049124111404820"><cite>Sociological -->
<!-- Methods and Research</cite> <strong>40</strong> (2011): -->
<!-- 211--239</a>, <a href="http://arxiv.org/abs/1004.4704">arxiv:1004.4704</a>. -->
<!-- Individuals near each other in a social network tend to behave similarly; you -->
<!-- can predict what one of them will do from what their neighbors do.  Is this -->
<!-- because they are influenced by their neighbors ("contagion"), or because social -->
<!-- ties tend to form between people who are already similar ("homophily"), and so -->
<!-- act alike, or some of both?  We show that observational data can hardly ever -->
<!-- answer this question, unless accompanied by very strong assumptions, like -->
<!-- measuring everything that leads people to form social ties. -->
<!-- (<a href="../weblog/656.html">More</a>.) -->

<!-- <P>[31] <a href="http://www.stat.columbia.edu/~gelman/">Andrew Gelman</a> and -->
<!-- CRS, "Philosophy and the practice of Bayesian -->
<!-- statistics", <a href="http://dx.doi.org/10.1111/j.2044-8317.2011.02037.x"><cite>British Journal of Mathematical and Statistical Psychology</cite> <strong>66</strong> -->
<!-- (2013): 8--38</a>, <a href="http://arxiv.org/abs/1006.3868">arxiv:1006.3868</a> -->
<!-- (with commentaries and response).  What bugs me the most about many -->
<!-- presentations of Bayesianism is the pretense that it gives an automatic method -->
<!-- of induction, that all you need or should rationally want is the posterior -->
<!-- probability of your theory.  For actual mortals, testing, checking and revising -->
<!-- your model remains essential, and this matches what good Bayesian data analysts -->
<!-- actually <em>do</em>, though their ideology discourages them from doing it. -->

<!-- <P>[32] "Scaling and Hierarchy in Urban -->
<!-- Economies", <a href="http://arxiv.org/abs/1102.4101">arxiv:1102.4101</a>. -->

<!-- <P>[33] <a href="http://mypage.iu.edu/~dajmcdon/">Daniel J. McDonald</a>, CRS -->
<!-- and Mark Schervish, "Estimating beta-mixing -->
<!-- coefficients", <a href="http://jmlr.csail.mit.edu/proceedings/papers/v15/mcdonald11a.html">pp. 516--524</a> -->
<!-- in the 14th Conference on Artificial Intelligence and Statistics (AISTATS -->
<!-- 2011), <a href="http://arxiv.org/abs/1103.0941">arxiv:1103.0941</a> -->

<!-- <P>[34] <a href="http://mypage.iu.edu/~dajmcdon/">Daniel J. McDonald</a>, CRS and Mark Schervish, "Generalization error bounds for stationary autoregressive models", <a href="http://arxiv.org/abs/1103.0942">arxiv:1103.0942</a> -->

<!-- <P>[35] CRS, Abigail Z. Jacobs, Kristina L. Klinkner, and <a href="http://www.santafe.edu/~aaronc/">Aaron Clauset</a>, "Adapting to Non-stationarity with Growing Expert Ensembles", <a href="http://arxiv.org/abs/1103.0949">arxiv:1103.0949</a> -->

<!-- <P>[36] <a href="http://mypage.iu.edu/~dajmcdon/">Daniel J. McDonald</a> and CRS -->
<!-- "Rademacher complexity of stationary sequences", -->
<!-- <a href="http://arxiv.org/abs/1106.0730">arxiv:1106.0730</a> -->

<!-- <P>[37] CRS and <a href="http://www.stat.cmu.edu/~arinaldo/">Alessandro -->
<!-- Rinaldo</a>, "Consistency under Sampling of Exponential Random Graph -->
<!-- Models", <a href="http://dx.doi.org/10.1214/12-AOS1044"><cite>Annals of -->
<!-- Statistics</cite> <strong>41</strong> (2013): 508--535</a>, <a href="http://arxiv.org/abs/1111.3054">arxiv:1111.3054</a>.  <a href="../weblog/837.html">More</a>. -->

<!-- <P>[38] CRS and Aryeh (Leonid) Kontorovich, "Predictive PAC Learning and -->
<!-- Process -->
<!-- Decompositions", <a href="http://papers.nips.cc/paper/5102-predictive-pac-learning-and-process-decompositions">pp. 1619--1627 -->
<!-- in NIPS 2013</a>, <a href="http://arxiv.org/abs/1309.4859">arxiv:1309.4859</a> -->

<!-- <P>[39] Georg M. Goerg, CRS and Larry Wasserman, "Lebesgue Smoothing" (by -->
<!-- request) -->

<!-- <P>[40] Henry Farrell and CRS, "Selection, Evolution, and Rational Choice -->
<!-- Institutionalism" (by request) -->

<!-- <P>[41] <a href="http://mypage.iu.edu/~dajmcdon/">Daniel J. McDonald</a>, CRS and Mark Schervish, "Estimating Beta-Mixing Coefficients via Histograms", -->
<!-- <a href="http://dx.doi.org/10.1214/15-EJS1094"><cite>Electronic Journal of -->
<!-- Statistics</cite> <strong>9</strong> (2015): -->
<!-- 2855--2883</a>, <a href="http://arxiv.org/abs/1109.5998">arxiv:1109.5998</a> -->

<!-- <P>[42] <a href="http://mypage.iu.edu/~dajmcdon/">Daniel J. McDonald</a>, CRS and Mark Schervish, "Estimated VC Dimension for Risk Bounds", <a href="http://arxiv.org/abs/1111.3404">arxiv:1111.3404</a>. -->
<!-- <a href="../weblog/839.html">More</a>. -->

<!-- <P>[43] "Comment on 'Why and When "Flawed" Social Network Analyses Still -->
<!-- Yield Valid Tests of No -->
<!-- Contagion'", <a href="http://dx.doi.org/10.1515/2151-7509.1053"><cite>Statistics, -->
<!-- Politics, and Policy</cite> <strong>3</strong> (2012): 5</a> -->
<!-- [<a href="../../www.stat.cmu.edu/_cshalizi/spp2012.pdf">PDF reprint</a>] -->

<!-- <p>[44] Georg M. Goerg and CRS, "LICORS: Light Cone Reconstruction of States -->
<!-- for Non-parametric Forecasting of Spatio-Temporal Systems", <a href="http://arxiv.org/abs/1206.2398">arxiv:1206.2398</a> -->

<!-- <p>[45] Xiaoran Yan, CRS, Jacob E. Jensen, Florent -->
<!-- Krzakala, <a href="http://www.santafe.edu/~moore/">Cristopher Moore</a>, Lenka -->
<!-- Zdeborova, Pan Zhang and Yaojia Zhu, "Model Selection for Degree-corrected -->
<!-- Block Models", <a href="http://dx.doi.org/10.1088/1742-5468/2014/05/P05007"><cite>Journal of Statistical Mechanics</cite> -->
<!-- 2014: P05007</a>, <a href="http://arxiv.org/abs/1207.3994">arxiv:1207.3994</a> -->

<!-- <P>[46] Georg M. Goerg and CRS, "Mixed LICORS: A Nonparametric Algorithm for -->
<!-- Predictive State Reconstruction", -->
<!-- <a href="http://jmlr.org/proceedings/papers/v31/goerg13a.html">pp. 289--297 -->
<!-- in AIStats -->
<!-- 2013</a>, <a href="http://arxiv.org/abs/1211.3760">arxiv:1211.3760</a> -->

<!-- <P>[47] <a href="http://mypage.iu.edu/~dajmcdon/">Daniel J. McDonald</a>, CRS, and Mark J. Schervish, -->
<!-- "Nonparametric Risk Bounds for Time-Series Forecasting", <a href="http://jmlr.org/papers/v18/13-336.html"><cite>Journal of Machine Learning Research</cite> <strong>18:32</strong> (2017): 1--40</a>, -->
<!-- <a href="http://arxiv.org/abs/1212.0463">arxiv:1212.0463</a> -->

<!-- <P>[48] Leila Wehbe, Aaditya Ramdas, Rebecca C. Steorts and CRS, "Regularized -->
<!-- Brain Reading with Shrinkage and -->
<!-- Smoothing", <a href="http://dx.doi.org/10.1214/15-AOAS837"><cite>Annals of -->
<!-- Applied Statistics</cite> <strong>9</strong> (2015): -->
<!-- 1997--2022</a>, <a href="http://arxiv.org/abs/1401.6595">arxiv:1401.6595</a> -->

<!-- <P>[49] Dena Asta and CRS, "Geometric Network Comparison", pp. -->
<!-- 102--110 in <a href="http://auai.org/uai2015/proceedings.shtml">UAI 2015</a>, -->
<!-- <a href="http://arxiv.org/abs/1411.1350">arxiv:1411.1350</a> -->

<!-- <P>[50] George D. Montanez and CRS, "The LICORS Cabinet: Nonparametric Algorithms for Spatio-temporal Prediction", -->
<!-- <cite>International Joint -->
<!-- Conference on Neural Networks</cite> [IJCNN 2017], -->
<!-- <a href="http://arxiv.org/abs/1506.02686">arxiv:1506.02686</a> [Winner of the -->
<!-- Best Student Paper and Best Poster awards] -->

<!-- <P>[51] Christopher N. Warren, Daniel Shore, Jessica Otis, Lawrence Wang, Mike -->
<!-- Finegold and CRS, "Six Degrees of Francis Bacon: A Statistical Method for -->
<!-- Reconstructing Large Historical Social -->
<!-- Networks", <a href="http://www.digitalhumanities.org/dhq/vol/10/3/000244/000244.html"><cite>Digital -->
<!-- Humanities Quarterly</cite> <strong>10:3</strong> (2016)</a> --- and <a href="http://sixdegreesoffrancisbacon.com/">Six Degrees of Francis Bacon</a> website -->

<!-- <P>[52] Edward McFowland III and CRS, "Estimating Causal Peer Influence in Homophilous Social Networks by Inferring Latent Locations", <a href="https://doi.org/10.1080/01621459.2021.1953506"><cite>Journal of the -->
<!-- American Statistical Association</cite> <strong>forthcoming</strong> (2022)</a>, -->
<!-- <a href="http://arxiv.org/abs/1607.06565">arxiv:1607.06565</a> -->

<!-- <P>[53] Neil Spencer and CRS, "Projective Sparse Latent Space Network Models", -->
<!-- <a href="http://arxiv.org/abs/1709.09702">arxiv:1709.09702</a> -->

<!-- <P>[54] Alden Green and CRS, "Bootstrapping Exchangeable Random Graphs", -->
<!-- <a href="https://doi.org/10.1214/21-EJS1896"><cite>Electronic Journal of Statistics</cite> <strong>16</strong> (2022): 1058--1905</a>, <a href="https://arxiv.org/abs/1711.00813">arxiv:1711.00813</a> -->

<!-- <P>[55] CRS and Dena Asta, "Consistency of Maximum Likelihood for Continuous-Space Network Models", <a href="http://arxiv.org/abs/1711.02123">arxiv:1711.02123</a> -->

<!-- <P>[56] Robert Lunde and CRS, "Bootstrapping Generalization Error Bounds for Time Series", <a href="http://arxiv.org/abs/1711.02834">arxiv:1711.02834</a> -->

<!-- <P>[57] Octavio C&eacute;sar Mesner, Alex Davis, Elizabeth Casman, Hyagriv Simhan, CRS, Lauren Keenan-Devlin, Ann Borders and Tamar Krishnamurti, "Using graph learning to understand adverse pregnancy outcomes and stress pathways", <a href="https://doi.org/10.1371/journal.pone.0223319"><cite>PLoS One</cite> <strong>14</strong> (2019): e0223319</a> -->

<!-- <P>[58] Octavio C&eacute;sar Mesner and CRS, "Conditional Mutual Information Estimation for Mixed Discrete and Continuous Variables with Nearest Neighbors",  <a href="https://doi.org/10.1109/TIT.2020.3024886"><cite>IEEE Transactions on Information Theory</cite> <strong>67</strong> (2021): 464--484</a>, <a href="http://arxiv.org/abs/1912.03387">arxiv:1912.03387</a> -->

<!-- <P>[59] CRS, "A Note on Simulation-Based Inference by Matching Random Features", <a href="http://arxiv.org/abs/2111.09220">arxiv:2111.09220</a> -->

<!-- <P>[60] CRS, "Evaluating Posterior Distributions by Selectively Breeding Prior Samples", <a href="http://arxiv.org/abs/2203.09077">arxiv:2203.09077</a> -->

<!-- <P>[61] CRS, "A Simple Non-Stationary Mean Ergodic Theorem, with Bonus Weak Law of Large Numbers", <a href="http://arxiv.org/abs/2203.09085">arxiv:2203.09085</a> -->



</body>
<!-- Mirrored from bactra.org/research/ by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 14 Apr 2022 09:12:01 GMT -->
</html>
